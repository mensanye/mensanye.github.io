{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e92a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c886efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv('ads_content_7224.csv')\n",
    "df2=pd.read_csv('socialbeta_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad22e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_ls=df1['ad_content'].to_list()\n",
    "_=df2['content'].to_list()\n",
    "content_ls +=_\n",
    "df_content=pd.DataFrame(content_ls,columns=['content'])\n",
    "df_content['content'].astype('str')\n",
    "df_content.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235aba70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8387, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a090be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import jieba\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5b0743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/fy/71rk0bjs7rv6r71b4g21lqcc0000gn/T/jieba.cache\n",
      "Loading model cost 0.741 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 对文章进行分词\n",
    "#载入自定义的词典\n",
    "jieba.load_userdict('/Users/julia/learndata/dic_jieba/jiebaDict.txt')\n",
    "\n",
    "df_content['content'] = df_content['content'].apply(jieba.lcut)\n",
    "#过滤停用词\\长度小于1的词\\非中文词\n",
    "pattern = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "stopwords = [line.strip().encode('utf-8').decode('utf-8') for line in open('/Users/julia/learndata/dic_jieba/cn_stopwords.txt').readlines()]\n",
    "# 判断字符串是不是纯中文\n",
    "df_content['content']= df_content['content'].apply(\n",
    "    lambda cut_words: [word for word in cut_words if word not in stopwords and len(word) > 1 and pattern.search(word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec1b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每篇文章结果进行去重,并获取所有的分词结果\n",
    "content_cut = df_content['content'].apply(lambda s: list(set(s)))\n",
    "content_word=[]\n",
    "for i in content_cut.index:\n",
    "    content_word += content_cut[i]\n",
    "content_word = set(content_word)\n",
    "\n",
    "\n",
    "#构造字典，用于存放包含某个词汇文档的数量\n",
    "path_num = os.path.join(r\"/Users/julia/Desktop/\", 'num_dict.txt')\n",
    "\n",
    "try:\n",
    "    # 先读取上次结果， 若不存在则重新构造\n",
    "    dict_df = pd.read_csv(path_num, encoding='gbk', sep=' ', header=None, names=['word', 'idf'])\n",
    "    dic = dict(zip(dict_df['word'], dict_df['idf']))\n",
    "except Exception as e:\n",
    "\t# 新构造的字典初始值全为0\n",
    "    dic = dict(zip(content_word, [0] * len(content_word)))\n",
    "\n",
    "# 计算IDF值\n",
    "# 1.更新出现每个词文章的数目\n",
    "for i in content_cut.index:\n",
    "    for word in content_cut[i]:\n",
    "        try:\n",
    "            dic[word] += 1\n",
    "        except:\n",
    "            dic[word] = 1\n",
    "# 2.保存次数，用于下一次的增量更新\n",
    "file = open(path_num, 'w', encoding='utf-8')\n",
    "for key, value in dic.items():\n",
    "    try:\n",
    "        text = key + ' ' + str(value) + '\\n'\n",
    "        file.write(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "file.close()\n",
    "\n",
    "# 3.计算IDF值\n",
    "path_idf = os.path.join(r\"/Users/julia/Desktop/\", \"idf_dict.txt\")\n",
    "n = df_content.shape[0]  # 文章总数\n",
    "idf_dic = {key: math.log(n / value, 10) for key, value in dic.items()}\n",
    " # 保存，添加到结巴的提取关键词词库\n",
    "file = open(path_idf, 'w', encoding='utf-8')\n",
    "for key, value in idf_dic.items():\n",
    "    try:\n",
    "        text = key + ' ' + str(value) + '\\n'\n",
    "        file.write(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
