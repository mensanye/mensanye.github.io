{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f501d31",
   "metadata": {},
   "source": [
    "### 自定义广告项目IDF 语料库\n",
    "\n",
    "由于广告行业的特殊性，不适合使用通用的IDF语料库，所以用自定义一个语料库逆文档。\n",
    "\n",
    "用了2019年至今，国内8000多个广告项目的文本资料来构建自定义的IDF文本语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e92a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c886efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv('ads_content_7224.csv')\n",
    "df2=pd.read_csv('socialbeta_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad22e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_ls=df1['ad_content'].to_list()\n",
    "_=df2['content'].to_list()\n",
    "content_ls +=_\n",
    "df_content=pd.DataFrame(content_ls,columns=['content'])\n",
    "df_content['content'].astype('str')\n",
    "df_content.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235aba70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8387, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a090be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import jieba\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5b0743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/fy/71rk0bjs7rv6r71b4g21lqcc0000gn/T/jieba.cache\n",
      "Loading model cost 0.741 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 对文章进行分词\n",
    "#载入自定义的词典\n",
    "jieba.load_userdict('/Users/julia/learndata/dic_jieba/jiebaDict.txt')\n",
    "\n",
    "df_content['content'] = df_content['content'].apply(jieba.lcut)\n",
    "#过滤停用词\\长度小于1的词\\非中文词\n",
    "pattern = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "stopwords = [line.strip().encode('utf-8').decode('utf-8') for line in open('/Users/julia/learndata/dic_jieba/cn_stopwords.txt').readlines()]\n",
    "# 判断字符串是不是纯中文\n",
    "df_content['content']= df_content['content'].apply(\n",
    "    lambda cut_words: [word for word in cut_words if word not in stopwords and len(word) > 1 and pattern.search(word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec1b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每篇文章结果进行去重,并获取所有的分词结果\n",
    "content_cut = df_content['content'].apply(lambda s: list(set(s)))\n",
    "content_word=[]\n",
    "for i in content_cut.index:\n",
    "    content_word += content_cut[i]\n",
    "content_word = set(content_word)\n",
    "\n",
    "\n",
    "#构造字典，用于存放包含某个词汇文档的数量\n",
    "path_num = os.path.join(r\"/Users/julia/Desktop/\", 'num_dict.txt')\n",
    "\n",
    "try:\n",
    "    # 先读取上次结果， 若不存在则重新构造\n",
    "    dict_df = pd.read_csv(path_num, encoding='gbk', sep=' ', header=None, names=['word', 'idf'])\n",
    "    dic = dict(zip(dict_df['word'], dict_df['idf']))\n",
    "except Exception as e:\n",
    "\t# 新构造的字典初始值全为0\n",
    "    dic = dict(zip(content_word, [0] * len(content_word)))\n",
    "\n",
    "# 计算IDF值\n",
    "# 1.更新出现每个词文章的数目\n",
    "for i in content_cut.index:\n",
    "    for word in content_cut[i]:\n",
    "        try:\n",
    "            dic[word] += 1\n",
    "        except:\n",
    "            dic[word] = 1\n",
    "# 2.保存次数，用于下一次的增量更新\n",
    "file = open(path_num, 'w', encoding='utf-8')\n",
    "for key, value in dic.items():\n",
    "    try:\n",
    "        text = key + ' ' + str(value) + '\\n'\n",
    "        file.write(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "file.close()\n",
    "\n",
    "# 3.计算IDF值\n",
    "path_idf = os.path.join(r\"/Users/julia/Desktop/\", \"idf_dict.txt\")\n",
    "n = df_content.shape[0]  # 文章总数\n",
    "idf_dic = {key: math.log(n / value, 10) for key, value in dic.items()}\n",
    " # 保存，添加到结巴的提取关键词词库\n",
    "file = open(path_idf, 'w', encoding='utf-8')\n",
    "for key, value in idf_dic.items():\n",
    "    try:\n",
    "        text = key + ' ' + str(value) + '\\n'\n",
    "        file.write(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e244fb",
   "metadata": {},
   "source": [
    "### 关键词提取效果测试\n",
    "\n",
    "从测试结果看，还是很明显能看出不同广告项目间的差别，比如：\n",
    "\n",
    "- 有的项目关键词体现创意，大多是名/动词，构建意象，言之有物\n",
    "\n",
    "- 有的项目关键词堆砌营销术语，云山雾罩，相对比较空洞乏味\n",
    "\n",
    "- 有的项目关键词反复强调项目广告主或项目代理商，展示强大的背景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb92be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f4f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('ads_content_7224.csv')\n",
    "test1= df.iloc[180,0]\n",
    "test2= df.iloc[235,0]\n",
    "test3= df.iloc[21,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ec713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "长白山 0.194842\n",
      "新风 0.175790\n",
      "空调 0.082236\n",
      "空气 0.068849\n",
      "呼吸 0.062611\n",
      "增氧 0.039733\n",
      "换气 0.034901\n",
      "新鲜空气 0.031853\n",
      "风景区 0.026176\n",
      "长白山天池 0.018342\n",
      "广州 0.016565\n",
      "自然 0.015927\n",
      "休息室 0.015926\n",
      "家电 0.015146\n",
      "带给 0.014737\n",
      "城市 0.014237\n",
      "跨界 0.012472\n",
      "用户 0.011472\n",
      "压抑 0.010976\n",
      "组长 0.010863\n"
     ]
    }
   ],
   "source": [
    "content = test1\n",
    "\n",
    "jieba.analyse.set_stop_words('/Users/julia/learndata/dic_jieba/cn_stopwords.txt') \n",
    "\n",
    "jieba.analyse.set_idf_path('/Users/julia/learndata/dic_jieba/idf_dict.txt')\n",
    "\n",
    "res = jieba.analyse.extract_tags(content, topK=20, withWeight=True)\n",
    "\n",
    "for word,weight in res:\n",
    "    print('%s %.6f'%(word, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b775c3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "康养 0.090259\n",
      "平安 0.038285\n",
      "高客 0.015928\n",
      "商业 0.015130\n",
      "养老 0.015034\n",
      "至善 0.014706\n",
      "价值体系 0.014706\n",
      "品牌 0.014198\n",
      "战略 0.013852\n",
      "高端 0.013468\n",
      "价值 0.013203\n",
      "真正 0.011782\n",
      "净值 0.011700\n",
      "复杂 0.010779\n",
      "构建 0.010645\n",
      "量变 0.010619\n",
      "New 0.010619\n",
      "虚怀若谷 0.009804\n",
      "竞争 0.009672\n",
      "之道 0.009178\n"
     ]
    }
   ],
   "source": [
    "content = test2\n",
    "\n",
    "jieba.analyse.set_stop_words('/Users/julia/learndata/dic_jieba/cn_stopwords.txt') \n",
    "\n",
    "jieba.analyse.set_idf_path('/Users/julia/learndata/dic_jieba/idf_dict.txt')\n",
    "\n",
    "res = jieba.analyse.extract_tags(content, topK=20, withWeight=True)\n",
    "\n",
    "for word,weight in res:\n",
    "    print('%s %.6f'%(word, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7de30063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "买药 0.080098\n",
      "美团 0.049181\n",
      "24 0.035481\n",
      "胜加 0.024679\n",
      "真诚 0.018498\n",
      "大众 0.012539\n",
      "华Sir 0.011827\n",
      "小时 0.010003\n",
      "服务 0.009808\n",
      "夜间 0.008415\n",
      "用药 0.007509\n",
      "品牌 0.007413\n",
      "用到 0.007211\n",
      "值得 0.007096\n",
      "真的 0.006838\n",
      "知道 0.006636\n",
      "药店 0.006610\n",
      "情感 0.006607\n",
      "价值 0.006536\n",
      "短片 0.006405\n"
     ]
    }
   ],
   "source": [
    "content = test3\n",
    "\n",
    "jieba.suggest_freq('华Sir',tune=True)\n",
    "\n",
    "jieba.analyse.set_stop_words('/Users/julia/learndata/dic_jieba/cn_stopwords.txt') \n",
    "\n",
    "jieba.analyse.set_idf_path('/Users/julia/learndata/dic_jieba/idf_dict.txt')\n",
    "\n",
    "res = jieba.analyse.extract_tags(content, topK=20, withWeight=True)\n",
    "\n",
    "for word,weight in res:\n",
    "    print('%s %.6f'%(word, weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28955e91",
   "metadata": {},
   "source": [
    "### 比较文本余弦相似度\n",
    "\n",
    "广告是瞄准人性的生意，方向一致，就算不同的项目也经常有类似之处，那到底差别有多大呢。\n",
    "\n",
    "同一类型的广告主（如电商），同一营销节点（如春节），不同代理公司出品的项目在多大程度上相似。\n",
    "\n",
    "同一代理公司，在面对不同的广告主时，给出的项目究竟是量身定制还是一招鲜吃遍天呢？\n",
    "\n",
    "尝试了三种方法，利用余弦相似度，比较不同广告项目文本的相似程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19d398d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于TF-IDF计算两个文本的余弦相似度\n",
    "\n",
    "#分别取关键词并生成向量\n",
    "def get_cos_similarity_tfidf(s1,s2):\n",
    "    \n",
    "    jieba.analyse.set_stop_words('/Users/julia/learndata/dic_jieba/cn_stopwords.txt') \n",
    "    jieba.analyse.set_idf_path('/Users/julia/learndata/dic_jieba/idf_dict.txt')\n",
    "    \n",
    "    res1 = jieba.analyse.extract_tags(s1, topK=20, withWeight=False)\n",
    "    res2 = jieba.analyse.extract_tags(s2, topK=20, withWeight=False)\n",
    "    key_word1=[]\n",
    "    key_word2=[]\n",
    "    \n",
    "    for word in res1:\n",
    "        key_word1.append(word)\n",
    "    for word in res2:\n",
    "        key_word2.append(word)\n",
    "        \n",
    "#     print(key_word1)\n",
    "#     print(key_word2)\n",
    "    \n",
    "    #取关键词的并集\n",
    "    key_word= list(set(key_word1+key_word2))\n",
    "    \n",
    "    #两个储存用的空向量\n",
    "    key_word_vector1= np.zeros(len(key_word))\n",
    "    key_word_vector2= np.zeros(len(key_word))\n",
    "    \n",
    "    #计算词频\n",
    "    for i in range(len(key_word)):\n",
    "        \n",
    "        for j in range(len(key_word1)):\n",
    "            if key_word[i]==key_word1[j]:\n",
    "                key_word_vector1[i]+=1\n",
    "                       \n",
    "        for k in range(len(key_word2)):\n",
    "            if key_word[i]==key_word2[k]:\n",
    "                key_word_vector2[i]+=1\n",
    "                       \n",
    "    x= key_word_vector1\n",
    "    y= key_word_vector2\n",
    "                       \n",
    "                       \n",
    "#     print(x)\n",
    "#     print(y)\n",
    "\n",
    "    nx= x / (np.sqrt(np.sum(x**2)) + 1e-8)\n",
    "    ny =y / (np.sqrt(np.sum(y**2)) + 1e-8)\n",
    "    cos_similarity_tfidf=float(np.dot(x,y)/(np.linalg.norm(x)*np.linalg.norm(y)))\n",
    "#     cos_similarity= np.dot(nx, ny)\n",
    "    return cos_similarity_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea985a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算两文本的余弦相似度为0.2897808849066627\n",
      "基于TF-IDF计算为0.09999999999999998\n",
      "基于TextRankn计算为0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "#以下为测试\n",
    "df= pd.read_csv('ads_content_7224.csv')\n",
    "df[df['ad_content'].str.contains('平安',na=False)]\n",
    "test1 = df.iloc[731,0]\n",
    "test2 = df.iloc[880,0]\n",
    "\n",
    "print('计算两文本的余弦相似度为{}'.format(get_cos_similarity(test1,test2)))\n",
    "print('基于TF-IDF计算为{}'.format(get_cos_similarity_tfidf(test1,test2)))\n",
    "print('基于TextRankn计算为{}'.format(get_cos_similarity_textrank(test1,test2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
